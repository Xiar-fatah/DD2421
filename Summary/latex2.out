\BOOKMARK [1][-]{section.1}{Lecture 2}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{How to ask the best questions?}{section.1}% 2
\BOOKMARK [3][-]{subsubsection.1.1.1}{Gini impurity}{subsection.1.1}% 3
\BOOKMARK [3][-]{subsubsection.1.1.2}{Entropy}{subsection.1.1}% 4
\BOOKMARK [3][-]{subsubsection.1.1.3}{Information gain}{subsection.1.1}% 5
\BOOKMARK [3][-]{subsubsection.1.1.4}{Best question}{subsection.1.1}% 6
\BOOKMARK [3][-]{subsubsection.1.1.5}{Pruning}{subsection.1.1}% 7
\BOOKMARK [3][-]{subsubsection.1.1.6}{Validation set}{subsection.1.1}% 8
\BOOKMARK [1][-]{section.2}{Lecture 3}{}% 9
\BOOKMARK [2][-]{subsection.2.1}{What is Statistical Learning}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.2}{Why Estimate f? }{section.2}% 11
\BOOKMARK [3][-]{subsubsection.2.2.1}{Prediction}{subsection.2.2}% 12
\BOOKMARK [3][-]{subsubsection.2.2.2}{Inference}{subsection.2.2}% 13
\BOOKMARK [2][-]{subsection.2.3}{How Do We Estimate f?}{section.2}% 14
\BOOKMARK [3][-]{subsubsection.2.3.1}{Parametric Methods}{subsection.2.3}% 15
\BOOKMARK [3][-]{subsubsection.2.3.2}{Non-parametric Methods}{subsection.2.3}% 16
\BOOKMARK [2][-]{subsection.2.4}{Assessing Model Accuracy}{section.2}% 17
\BOOKMARK [2][-]{subsection.2.5}{Measuring the Quality of Fit}{section.2}% 18
\BOOKMARK [2][-]{subsection.2.6}{Curse of Dimensionality}{section.2}% 19
\BOOKMARK [2][-]{subsection.2.7}{The Bias-Variance Trade Off}{section.2}% 20
\BOOKMARK [2][-]{subsection.2.8}{The Validation Set Approach}{section.2}% 21
\BOOKMARK [1][-]{section.3}{Lecture 4}{}% 22
\BOOKMARK [2][-]{subsection.3.1}{Linear Regression, A Parametric Method}{section.3}% 23
\BOOKMARK [2][-]{subsection.3.2}{RANdom SAmpling Consensus}{section.3}% 24
\BOOKMARK [2][-]{subsection.3.3}{Disadvantages with RANSAC}{section.3}% 25
\BOOKMARK [2][-]{subsection.3.4}{Differences with Parametric and Non-parametric Methods}{section.3}% 26
\BOOKMARK [2][-]{subsection.3.5}{k-NN Regression, A Non-parametric}{section.3}% 27
\BOOKMARK [2][-]{subsection.3.6}{Parametric or Non-parametric Methods?}{section.3}% 28
\BOOKMARK [2][-]{subsection.3.7}{Shrinkage Methods}{section.3}% 29
\BOOKMARK [2][-]{subsection.3.8}{Ride Regression}{section.3}% 30
\BOOKMARK [2][-]{subsection.3.9}{The Lasso}{section.3}% 31
\BOOKMARK [1][-]{section.4}{Lecture 5}{}% 32
\BOOKMARK [2][-]{subsection.4.1}{Probability Theory in Machine Learning}{section.4}% 33
\BOOKMARK [2][-]{subsection.4.2}{Axiomatic definition of probabilities}{section.4}% 34
\BOOKMARK [2][-]{subsection.4.3}{Random \(Stochastic\) Variables}{section.4}% 35
\BOOKMARK [2][-]{subsection.4.4}{Types of Random Variables}{section.4}% 36
\BOOKMARK [2][-]{subsection.4.5}{Joint Probabilities}{section.4}% 37
\BOOKMARK [2][-]{subsection.4.6}{Marginalization}{section.4}% 38
\BOOKMARK [2][-]{subsection.4.7}{Conditional Probabilities}{section.4}% 39
\BOOKMARK [2][-]{subsection.4.8}{Common Distributions}{section.4}% 40
\BOOKMARK [2][-]{subsection.4.9}{Central Limit Theorem}{section.4}% 41
\BOOKMARK [2][-]{subsection.4.10}{Expectation}{section.4}% 42
\BOOKMARK [2][-]{subsection.4.11}{General Machine Learning Problem}{section.4}% 43
\BOOKMARK [2][-]{subsection.4.12}{Bayes's Rule}{section.4}% 44
