\contentsline {section}{\numberline {1}Lecture 2}{5}{section.1}
\contentsline {subsection}{\numberline {1.1}Decision Tree}{5}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}How to build a Tree}{5}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}How to ask the best questions?}{5}{subsection.1.3}
\contentsline {subsubsection}{\numberline {1.3.1}Gini impurity}{5}{subsubsection.1.3.1}
\contentsline {subsubsection}{\numberline {1.3.2}Entropy}{5}{subsubsection.1.3.2}
\contentsline {subsubsection}{\numberline {1.3.3}Information gain}{6}{subsubsection.1.3.3}
\contentsline {subsubsection}{\numberline {1.3.4}Best question}{6}{subsubsection.1.3.4}
\contentsline {subsection}{\numberline {1.4}Overfitting}{6}{subsection.1.4}
\contentsline {subsubsection}{\numberline {1.4.1}Pruning}{6}{subsubsection.1.4.1}
\contentsline {subsubsection}{\numberline {1.4.2}Validation set}{6}{subsubsection.1.4.2}
\contentsline {section}{\numberline {2}Lecture 3}{6}{section.2}
\contentsline {subsection}{\numberline {2.1}Introduction}{6}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Curse of Dimensionality}{7}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}The Bias-Variance Trade-off}{7}{subsection.2.3}
\contentsline {section}{\numberline {3}Lecture 4}{8}{section.3}
\contentsline {subsection}{\numberline {3.1}Linear Regression, A Parametric Method}{8}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}RANdom SAmpling Consensus}{8}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}Disadvantages with RANSAC}{9}{subsection.3.3}
\contentsline {subsection}{\numberline {3.4}k-NN Regression, A Non-parametric}{9}{subsection.3.4}
\contentsline {subsection}{\numberline {3.5}Parametric or Non-parametric Methods?}{10}{subsection.3.5}
\contentsline {subsection}{\numberline {3.6}Shrinkage Methods}{10}{subsection.3.6}
\contentsline {subsection}{\numberline {3.7}Ridge Regression}{10}{subsection.3.7}
\contentsline {subsection}{\numberline {3.8}The Lasso}{11}{subsection.3.8}
\contentsline {section}{\numberline {4}Lecture 5}{11}{section.4}
\contentsline {subsection}{\numberline {4.1}Axiomatic definition of probabilities}{11}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Random (Stochastic) Variables}{11}{subsection.4.2}
\contentsline {subsection}{\numberline {4.3}Types of Random Variables}{12}{subsection.4.3}
\contentsline {subsection}{\numberline {4.4}Joint Probabilities}{12}{subsection.4.4}
\contentsline {subsection}{\numberline {4.5}Marginalization}{12}{subsection.4.5}
\contentsline {subsection}{\numberline {4.6}Conditional Probabilities}{12}{subsection.4.6}
\contentsline {subsection}{\numberline {4.7}Common Distributions}{13}{subsection.4.7}
\contentsline {subsection}{\numberline {4.8}Central Limit Theorem}{13}{subsection.4.8}
\contentsline {subsection}{\numberline {4.9}Expectation}{13}{subsection.4.9}
\contentsline {subsection}{\numberline {4.10}General Machine Learning Problem}{14}{subsection.4.10}
\contentsline {subsection}{\numberline {4.11}Bayes's Rule}{14}{subsection.4.11}
\contentsline {subsection}{\numberline {4.12}Probabilistic Regression}{14}{subsection.4.12}
\contentsline {subsection}{\numberline {4.13}Selecting the most probable hypothesis}{15}{subsection.4.13}
\contentsline {section}{\numberline {5}Lecture 6}{15}{section.5}
\contentsline {subsection}{\numberline {5.1}Introduction}{15}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}Discriminative vs Generative Models}{15}{subsection.5.2}
\contentsline {subsection}{\numberline {5.3}Parametric vs Non-parametric Inference}{15}{subsection.5.3}
\contentsline {subsection}{\numberline {5.4}Maximum Likelihood (ML) Estimate}{16}{subsection.5.4}
\contentsline {subsection}{\numberline {5.5}Curse of Dimensionality}{16}{subsection.5.5}
\contentsline {subsection}{\numberline {5.6}Naive Bayes Classifier}{16}{subsection.5.6}
